<!-- Generated by Graft | model=bedrock-claude-v4.5-sonnet-us | sig=aadd802fdfd148d0248909d509414bfa7c886e5bc1348e526a9b298e67546357 | rev=39b5c7a | 2025-11-04 -->
# Working with Claude Skills in Graft

## What Are Claude Skills?

Claude Skills are model-invoked capabilities that activate automatically based on context. Unlike slash commands you explicitly type, skills work behind the scenes—Claude recognizes when a particular capability would help and uses it transparently.

For example, when you describe documentation goals or ask about project structure, Claude might invoke the `steward` skill to help you design effective documentation pipelines. You don't need to remember special syntax; you just describe what you're trying to accomplish.

Learn more in the [Claude Skills documentation](https://docs.anthropic.com/claude/docs/skills).

## The Steward Skill

The steward skill helps you design and manage Graft documentation pipelines. It activates when you're working through documentation challenges—figuring out what to generate, how to structure prompts, what depends on what, or what impact a change might have.

Think of it as a documentation design partner. When you describe a vague goal like "I want to create onboarding docs from our technical specs," the steward helps you think through:

- What structure makes sense for your readers?
- How should documents depend on each other?
- What prompt instructions will achieve your goals?
- What will regenerate when you make changes?

The steward doesn't just execute commands—it helps you explore possibilities, consider tradeoffs, and arrive at solutions that fit your specific situation.

## Working with Design Problems

The most valuable use of the steward is working through ambiguous documentation challenges. Here are realistic examples showing how conversations unfold.

### From Vague Goal to Information Architecture

**You:** "We have a bunch of technical documentation about our API, and we need to create something for new customers. They're not engineers, mostly product managers who need to understand what's possible."

**Claude (using steward):** "Let's think about what non-technical readers need. Looking at your existing docs, I see detailed endpoint specifications, authentication flows, and data models. For product managers, we probably want to transform this into use-case oriented documentation. 

What if we created a hierarchy like:
- `docs/internal/api-specs.md` (your existing technical docs)
- `docs/customer/capabilities.prompt.md` → generates overview of what's possible
- `docs/customer/use-cases.prompt.md` → generates scenario-based examples

Should these customer docs reference each other, or stay independent?"

**You:** "I think use-cases should build on capabilities. Someone reads capabilities first, then sees how to apply them."

**Claude:** "Perfect. Let's create that dependency chain. Here's what I'm thinking:

```bash
bin/graft new capabilities customer
bin/graft new use-cases customer
```

For `docs/customer/capabilities.prompt.md`:
```yaml
---
deps:
  - docs/internal/api-specs.md
---

Transform the technical API specifications into a capabilities overview 
for non-technical product managers. Focus on:
- What business problems each capability solves
- Real-world outcomes, not implementation details
- When to use each capability

Write in plain language. Avoid technical jargon. Use concrete examples.
```

Then `docs/customer/use-cases.prompt.md` depends on the generated capabilities doc:
```yaml
---
deps:
  - docs/customer/capabilities.md
  - docs/internal/api-specs.md
---

Create scenario-based use cases showing how product managers can combine 
capabilities to solve common problems. Each use case should:
- Start with a business goal
- Reference specific capabilities from the capabilities overview
- Show a concrete workflow
- Explain expected outcomes

Use storytelling. Make it relatable.
```

Want me to scaffold these with those instructions?"

**You:** "Yes, but I'm worried the use-cases doc will be too long. We have like 30 endpoints."

**Claude:** "Good instinct. Let's be more specific about scope in the prompt. We can tell it to focus on the top 5 most common scenarios, or we could create multiple use-case documents—one per product area. What makes sense for your API structure?"

**You:** "We have three product areas: data integration, reporting, and alerts. Let's do one doc per area."

**Claude:** "Great, that's much more manageable. I'll create:
- `docs/customer/capabilities.prompt.md` (overview of all three areas)
- `docs/customer/integration-use-cases.prompt.md` (data integration scenarios)
- `docs/customer/reporting-use-cases.prompt.md` (reporting scenarios)
- `docs/customer/alerts-use-cases.prompt.md` (alert scenarios)

Each use-case doc will depend on both the capabilities overview and the relevant sections of your API specs. The prompts can specifically tell Claude to focus on their area. Sound good?"

**You:** "Perfect. Let's do it."

*Result: What started as "we need customer docs" became a specific, structured solution through exploration and refinement.*

### Refining Through Iteration

**You:** "I have this executive summary that's generated from our strategy docs, but my CEO says it's too detailed. She wants something she can read in 2 minutes before a board meeting."

**Claude (using steward):** "Let's look at the current prompt. *[reads docs/strategy/executive-summary.prompt.md]* 

I see it says 'comprehensive summary with key insights and recommendations.' That's pretty open-ended. Let's make it much more specific about constraints:

```yaml
---
deps:
  - docs/strategy/foundations.md
  - docs/strategy/market-analysis.md
---

Create an executive summary optimized for a 2-minute read before board meetings.

Constraints:
- Maximum 400 words total
- Lead with the single most important decision or insight
- Include only information that requires CEO awareness
- Omit implementation details, tactical plans, background context

Structure:
1. Key decision or insight (1 sentence)
2. Why it matters (1 short paragraph)
3. Three critical numbers or facts (bullet points)
4. What happens next (1 sentence)

Use active voice. Be direct. Assume the reader has context.
```

This will trigger a RESTYLE—Claude will regenerate the entire document with these new constraints. Want to try it?"

**You:** "Yes, but I'm nervous about losing good content that's already there."

**Claude:** "Smart thinking. Let's do this incrementally:

1. First, run `bin/graft diff executive_summary` to see the current packed prompt
2. Copy the existing generated doc to `docs/strategy/executive-summary-detailed.md` as a backup
3. Update the prompt with the new constraints
4. Run `bin/graft rebuild`
5. Compare the results

If the new version drops something important, we can adjust the prompt to say 'Include X' or we can create two separate docs—one detailed, one board-ready. The detailed version could even be an input to the board version."

**You:** "Oh, that's interesting. So the detailed summary feeds into the board summary?"

**Claude:** "Exactly. Your hierarchy would be:
```
docs/strategy/foundations.md (manual)
docs/strategy/market-analysis.md (manual)
  └─> docs/strategy/executive-summary-detailed.md (generated, comprehensive)
      └─> docs/strategy/executive-summary-board.md (generated, 2-min version)
```

The board version's prompt would be:
```yaml
---
deps:
  - docs/strategy/executive-summary-detailed.md
---

Distill the detailed executive summary into a 2-minute board briefing.
[... same constraints as before ...]
```

This way you keep both versions, and when strategy docs change, both summaries regenerate automatically. The detailed version gets all updates, and the board version distills them."

**You:** "That's much better. Let's do that structure."

*Result: Through iteration, we moved from "make it shorter" to a robust two-tier summary system.*

### Understanding Impact

**You:** "I need to update our market analysis with Q1 numbers. But I'm worried about how much documentation this will regenerate. We have investor updates coming and I don't want to create churn."

**Claude (using steward):** "Good question. Let's check what depends on that file:

```bash
bin/graft uses docs/strategy/market-analysis.md
```

This shows me that market-analysis.md is a dependency for:
- docs/strategy/executive-summary.md
- docs/strategy/investor-update.md
- docs/planning/quarterly-objectives.md

Let's think about what will actually change. When you update market-analysis.md with Q1 numbers:

1. **executive-summary.md**: This will trigger an UPDATE action—Claude will incorporate the new numbers but keep the rest of the document unchanged. The prompt tells it to synthesize key insights, so it will weave in Q1 data where relevant.

2. **investor-update.md**: Let me check this prompt... *[reads]* ...this one pulls quarterly metrics specifically, so yes, it will definitely regenerate with Q1 numbers. That's probably what you want for investor updates anyway.

3. **quarterly-objectives.md**: This depends on market analysis but also on team capacity docs. It will UPDATE to reflect Q1 context, but objectives probably won't change dramatically unless the numbers show major surprises.

So: meaningful updates to investor-facing docs (good), contextual updates elsewhere (safe). The system will only change what semantically needs to change based on Q1 data.

Want to see the exact diff that will be sent to Claude? We can run `bin/graft status` after you update market-analysis.md but before rebuilding."

**You:** "Yes, let me update the file first... okay, done. Now what?"

**Claude:** "Run `bin/graft status` to see what's marked for regeneration, then `bin/graft diff investor_update` to see the packed prompt context. This shows you exactly what Claude will see—the old version of market-analysis.md vs the new version, with instructions to apply an UPDATE.

If the diff looks too broad, you can make your edit more surgical—just change specific numbers rather than rewriting paragraphs. Or we can adjust prompt instructions to be more conservative about propagating changes."

**You:** "The diff looks good—just Q1 numbers highlighted. I'll rebuild."

**Claude:** "Perfect. After rebuild, if you want to review what actually changed in generated docs:

```bash
git diff docs/strategy/executive-summary.md
```

You'll see that only sections referencing quarterly metrics changed. Everything else stayed identical."

*Result: Understanding impact before making changes reduces anxiety and enables informed decisions.*

### Discovering Structure Through Exploration

**You:** "We did a bunch of customer interviews and dumped all the notes into `research/interviews/`. There are like 20 files. I need to turn this into something useful but I don't know what structure makes sense yet."

**Claude (using steward):** "Let's explore what you have before deciding on structure. Can you share a couple of representative interview files, or describe what kind of information they contain?"

**You:** "They're pretty unstructured—just notes from conversations. Topics are all over the place: feature requests, pain points, workflow descriptions, competitive comparisons. Some interviews focus on one topic, others jump around."

**Claude:** "Okay, this is a good case for using Graft to help discover structure through analysis. Here's an exploratory approach:

**Step 1: Initial synthesis**

Let's create a prompt that analyzes all interviews and identifies patterns:

```bash
bin/graft new interview-analysis research
```

In `docs/research/interview-analysis.prompt.md`:
```yaml
---
deps:
  - research/interviews/*.md
---

Analyze all customer interviews and identify:

1. **Recurring themes**: What topics come up repeatedly across multiple interviews?
2. **Distinct user segments**: Do different types of users have different needs?
3. **Pain point clusters**: What problems group together naturally?
4. **Feature request categories**: How do requests relate to each other?

Create a structured taxonomy that could form the basis for organizing 
these insights. For each theme/segment/cluster, note:
- How many interviews mentioned it
- Whether it's universal or segment-specific
- Relationships to other themes

The goal is to discover a natural information architecture, not force 
one. Let the data reveal its own structure.
```

**Step 2: Generate and review**

```bash
bin/graft rebuild
```

This gives us `docs/research/interview-analysis.md` showing patterns. You review it and tell me what structure emerges."

**You:** "Okay, let me try this... *[time passes]* ...interesting. The analysis identified three clear user segments and five major pain point themes. Some themes are universal, others are segment-specific."

**Claude:** "Perfect! Now we have a data-driven structure. Let's create documentation that follows what you discovered. Based on your analysis, I'm thinking:

```
docs/research/
  interview-analysis.md (generated - what we just made)
  segments/
    enterprise-users.prompt.md → enterprise-users.md
    smb-users.prompt.md → smb-users.md
    individual-users.prompt.md → individual-users.md
  themes/
    integration-challenges.prompt.md → integration-challenges.md
    reporting-needs.prompt.md → reporting-needs.md
    ...
```

Each segment doc would depend on interviews mentioning that segment:
```yaml
---
deps:
  - research/interviews/interview-*.md
  - docs/research/interview-analysis.md
---

Create a profile of enterprise users based on interview data.

Focus only on interviews mentioning enterprise/large organization contexts.
Synthesize:
- Common workflows and use cases
- Specific pain points for this segment
- Feature priorities
- Buying process and decision criteria

Reference the interview analysis for context but go deeper into this segment's 
specific needs. Quote interview participants (anonymously) where illustrative.
```

Theme docs would depend on ALL interviews but filter by theme:
```yaml
---
deps:
  - research/interviews/interview-*.md
  - docs/research/interview-analysis.md
---

Synthesize all interview feedback related to integration challenges.

Pull from any interview mentioning integration, API usage, data sync, 
or connection workflows. Organize by:
- Current workarounds
- Specific pain points
- Desired improvements
- Technical vs. usability issues

Show how this theme manifests differently across user segments.
```

Want me to scaffold this structure?"

**You:** "Yes, but what happens when we do more interviews next month?"

**Claude:** "Great question. You just add new interview files to `research/interviews/`, and when you run `bin/graft rebuild`:

1. **interview-analysis.md** regenerates with new data included, possibly identifying new themes
2. **All segment and theme docs** regenerate, incorporating insights from new interviews
3. You see what changed via git diff

If new interviews reveal entirely new themes, you'd create new theme docs and regenerate. The structure is flexible—it evolves with your research.

You could also add a prompt instruction to interview-analysis.md saying 'highlight any new themes that weren't present in previous analysis' to help you spot when structure needs expansion."

**You:** "This is way better than trying to organize this manually. Let's do it."

*Result: Starting with unstructured data, using Graft to analyze and discover patterns, then building documentation structure based on what emerged.*

### Building Multi-Level Hierarchies

**You:** "I want to create a technical architecture document, but it needs to pull from generated API documentation, our generated deployment guides, and some manually written design principles. Is that going to be complicated?"

**Claude (using steward):** "Not at all—this is exactly what multi-level DAGs are for. Let's map out what you have:

**Manual sources** (you write these):
- `docs/principles/design-principles.md`
- Maybe some other foundational docs?

**Generated docs** (already exist?):
- `docs/api/endpoints.md` (generated from what?)
- `docs/operations/deployment-guide.md` (generated from what?)

**New doc you want**:
- `docs/architecture/technical-overview.md` (synthesizes everything)

Tell me what generates your API docs and deployment guides so I understand the full chain."

**You:** "The API docs are generated from OpenAPI specs in `specs/openapi.yaml`, and deployment guides are generated from infrastructure-as-code in `terraform/`."

**Claude:** "Perfect. Your dependency chain is:

```
specs/openapi.yaml (manual)
  └─> docs/api/endpoints.md (generated)
      
terraform/*.tf (manual)
  └─> docs/operations/deployment-guide.md (generated)
      
docs/principles/design-principles.md (manual)

All three of those feed into:
  └─> docs/architecture/technical-overview.md (generated)
```

Let's create the architecture overview:

```bash
bin/graft new technical-overview architecture
```

In `docs/architecture/technical-overview.prompt.md`:
```yaml
---
deps:
  - docs/api/endpoints.md
  - docs/operations/deployment-guide.md
  - docs/principles/design-principles.md
---

Create a comprehensive technical architecture document that synthesizes 
API structure, deployment architecture, an
