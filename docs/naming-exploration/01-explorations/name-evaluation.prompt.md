---
deps:
  - docs/naming-exploration/00-sources/naming-criteria.md
  - docs/naming-exploration/01-explorations/metaphor-names.md
  - docs/naming-exploration/01-explorations/technical-names.md
  - docs/naming-exploration/01-explorations/hybrid-names.md
---
# Name Evaluation and Scoring

Review ALL name candidates from the three generation documents and evaluate them rigorously against the criteria.

## Evaluation Process

For each name, score on these dimensions (1-5 scale):

1. **Memorability**: How easily does it stick in your mind?
2. **Pronounceability**: How easy is it to say aloud?
3. **Distinctiveness**: How unique is it in the tool/docs space?
4. **Evocativeness**: Does it evoke the right mental model for git-backed AI doc pipelines?
5. **Brevity**: Is it short and easy to type? (â‰¤8 chars = 5, longer = lower)
6. **Clarity**: Do you have a sense of what it does from the name?
7. **Professional**: Does it feel credible for enterprise use?

**Calculate average score for each name.**

## Output Format

Create a comprehensive evaluation table with ALL candidates, sorted by average score (highest first).

Then provide:

### Top 10 Finalists
List the top 10 scoring names with detailed rationale for why they scored well.

### Notable Mentions
Any names that didn't make top 10 but have interesting qualities worth discussing.

### Eliminated Names
Brief note on common patterns in low-scoring names (what didn't work and why).

## Additional Analysis

For the top 5 candidates, also consider:
- **Domain availability** (make an educated guess - is .com/.dev likely taken?)
- **Search engine friendliness** (will it be findable?)
- **Potential confusion** (does it conflict with other known tools/terms?)
- **International pronunciation** (how does it work across languages?)

Be thorough, analytical, and honest. The goal is to narrow down to 3-5 exceptional candidates for final recommendation.
