<!-- Generated by Graft | model=bedrock-claude-v4.5-sonnet-us | sig=207a7c74acd7b3115fc3983069875e00c6315d14ffedd6efcb647ff59fb542ba | rev=4155622 | 2025-11-04 -->
# Validation Strategy

This document defines Graft's comprehensive validation strategy for ensuring documentation consistency through structural checks, change detection, and content verification.

## Overview

Graft's validation system operates in three progressive layers, from fast structural checks to full regeneration verification. Each layer catches different types of issues and provides actionable error messages to guide fixes.

## Validation Layers

### Layer 1: Structural Validation

**Purpose**: Catch structural issues without LLM calls  
**Performance**: <5 seconds for entire codebase  
**Execution**: Parse files, check dependencies, verify configuration

#### 1.1 dvc.yaml Synchronization

**Algorithm**:
```python
def validate_dvc_sync():
    # Find all .prompt.md files
    prompt_files = glob("**/*.prompt.md", recursive=True)
    
    # Parse dvc.yaml to extract stage names
    dvc_stages = parse_dvc_yaml("dvc.yaml")
    
    # Generate expected stage names from prompts
    expected_stages = {
        prompt_to_stage_name(p) for p in prompt_files
    }
    
    # Find discrepancies
    missing_in_dvc = expected_stages - dvc_stages.keys()
    extra_in_dvc = dvc_stages.keys() - expected_stages
    
    if missing_in_dvc or extra_in_dvc:
        raise ValidationError("E001", missing=missing_in_dvc, extra=extra_in_dvc)
```

**Error E001: dvc.yaml Out of Sync**
```
Error: dvc.yaml is not synchronized with prompt files

Found 2 new prompts not in pipeline:
  - docs/features/new-feature.prompt.md
  - docs/api/endpoints.prompt.md

Found 1 stage in dvc.yaml with no corresponding prompt:
  - docs/old-feature.md

Fix: Run `bin/graft sync` to regenerate dvc.yaml
```

**Exit code**: 1

#### 1.2 Dependency Existence

**Algorithm**:
```python
def validate_dependencies():
    errors = []
    
    for prompt_file in glob("**/*.prompt.md", recursive=True):
        frontmatter = parse_frontmatter(prompt_file)
        deps = frontmatter.get("deps", [])
        
        for dep in deps:
            if "*" in dep or "?" in dep:
                # Glob pattern - must match at least one file
                matches = glob(dep, recursive=True)
                if not matches:
                    errors.append({
                        "prompt": prompt_file,
                        "dep": dep,
                        "line": find_line_number(prompt_file, dep),
                        "type": "glob_no_match"
                    })
            else:
                # Literal path - must exist
                if not os.path.exists(dep):
                    errors.append({
                        "prompt": prompt_file,
                        "dep": dep,
                        "line": find_line_number(prompt_file, dep),
                        "type": "missing"
                    })
    
    if errors:
        raise ValidationError("E002", errors=errors)
```

**Error E002: Missing Dependency**
```
Error: Dependencies do not exist

In: docs/overview.prompt.md (line 4)
Missing: docs/architecture/diagram.md
Fix: Create the file or remove it from the deps list

In: docs/api.prompt.md (line 5)
Pattern: src/**/*.py (matches 0 files)
Fix: Verify the glob pattern or remove it from the deps list
```

**Exit code**: 1

#### 1.3 Circular Dependency Detection

**Algorithm**:
```python
def validate_acyclic():
    # Build dependency graph
    graph = {}  # prompt -> [outputs it depends on]
    outputs = {}  # output file -> prompt that generates it
    
    for prompt_file in glob("**/*.prompt.md", recursive=True):
        frontmatter = parse_frontmatter(prompt_file)
        out = frontmatter["out"]
        deps = frontmatter.get("deps", [])
        
        outputs[out] = prompt_file
        graph[prompt_file] = [d for d in deps if d.endswith(".md")]
    
    # Map to prompt-to-prompt dependencies
    prompt_graph = {}
    for prompt, dep_files in graph.items():
        prompt_graph[prompt] = [
            outputs[f] for f in dep_files if f in outputs
        ]
    
    # Topological sort to detect cycles
    try:
        topological_sort(prompt_graph)
    except CycleError as e:
        raise ValidationError("E003", cycle=e.cycle)
```

**Error E003: Circular Dependency**
```
Error: Circular dependency detected

Cycle: docs/architecture.prompt.md 
       → docs/architecture.md (output)
       → docs/overview.prompt.md (dependency)
       → docs/overview.md (output)
       → docs/architecture.prompt.md (dependency)

Fix: Remove one dependency to break the cycle
Suggestion: Remove docs/overview.md from docs/architecture.prompt.md deps
```

**Exit code**: 1

#### 1.4 Frontmatter Validity

**Algorithm**:
```python
def validate_frontmatter():
    errors = []
    supported_models = ["bedrock-claude-v4.5-sonnet-us"]
    
    for prompt_file in glob("**/*.prompt.md", recursive=True):
        try:
            frontmatter = parse_frontmatter(prompt_file)
            
            # Check required fields
            if "out" not in frontmatter:
                errors.append({
                    "prompt": prompt_file,
                    "type": "missing_field",
                    "field": "out"
                })
            
            # Validate model if specified
            if "model" in frontmatter:
                if frontmatter["model"] not in supported_models:
                    errors.append({
                        "prompt": prompt_file,
                        "type": "invalid_model",
                        "model": frontmatter["model"],
                        "supported": supported_models
                    })
        
        except yaml.YAMLError as e:
            errors.append({
                "prompt": prompt_file,
                "type": "yaml_error",
                "line": e.problem_mark.line if hasattr(e, 'problem_mark') else None,
                "message": str(e)
            })
    
    if errors:
        raise ValidationError("E006", errors=errors)
```

**Error E006: Invalid Frontmatter**
```
Error: Invalid YAML frontmatter

In: docs/features/new-feature.prompt.md (line 3)
Parse error: mapping values are not allowed here
Fix: Check YAML syntax in the frontmatter section

In: docs/api.prompt.md
Missing required field: out
Fix: Add 'out: <filename>' to the frontmatter
```

**Exit code**: 1

**Error E007: Invalid Model Name**
```
Error: Unknown model specified

In: docs/overview.prompt.md (line 4)
Model: gpt-4 (not supported)

Supported models:
  - bedrock-claude-v4.5-sonnet-us

Fix: Use a valid model name or remove the line to use default
```

**Exit code**: 1

### Layer 2: Change Detection

**Purpose**: Detect what changed without regenerating  
**Performance**: <10 seconds for entire codebase  
**Execution**: Git diff analysis, DVC status checks

#### 2.1 Source Change Detection

**Algorithm**:
```python
def detect_source_changes():
    changes = []
    
    for prompt_file in glob("**/*.prompt.md", recursive=True):
        frontmatter = parse_frontmatter(prompt_file)
        deps = frontmatter.get("deps", [])
        
        # Expand globs
        all_deps = []
        for dep in deps:
            if "*" in dep or "?" in dep:
                all_deps.extend(glob(dep, recursive=True))
            else:
                all_deps.append(dep)
        
        # Check git diff for each dependency
        source_changed = False
        for dep in all_deps:
            result = subprocess.run(
                ["git", "diff", "HEAD", "--", dep],
                capture_output=True
            )
            if result.stdout:  # Has diff
                source_changed = True
                break
        
        if source_changed:
            changes.append({
                "prompt": prompt_file,
                "output": frontmatter["out"],
                "reason": "sources_changed"
            })
    
    return changes
```

#### 2.2 Prompt Change Detection

**Algorithm**:
```python
def detect_prompt_changes():
    changes = []
    
    for prompt_file in glob("**/*.prompt.md", recursive=True):
        # Get HEAD version
        head_content = subprocess.run(
            ["git", "show", f"HEAD:{prompt_file}"],
            capture_output=True,
            text=True
        ).stdout
        
        if not head_content:
            # New file
            changes.append({
                "prompt": prompt_file,
                "reason": "new_prompt"
            })
            continue
        
        # Extract prompt body (after frontmatter)
        current_body = extract_prompt_body(read_file(prompt_file))
        head_body = extract_prompt_body(head_content)
        
        if current_body != head_body:
            changes.append({
                "prompt": prompt_file,
                "reason": "instructions_changed",
                "diff": unified_diff(head_body, current_body)
            })
    
    return changes
```

#### 2.3 Output Staleness Detection

**Algorithm**:
```python
def detect_stale_outputs():
    stale = []
    
    source_changes = detect_source_changes()
    prompt_changes = detect_prompt_changes()
    
    # Build map of outputs to change reasons
    change_map = {}
    
    for change in source_changes:
        output = change["output"]
        change_map.setdefault(output, []).append("sources")
    
    for change in prompt_changes:
        frontmatter = parse_frontmatter(change["prompt"])
        output = frontmatter["out"]
        change_map.setdefault(output, []).append("prompt")
    
    # Check if outputs exist and are current
    for output, reasons in change_map.items():
        if not os.path.exists(output):
            status = "never_generated"
        else:
            # Check if output is in git and matches working directory
            git_version = subprocess.run(
                ["git", "show", f"HEAD:{output}"],
                capture_output=True
            ).stdout
            
            if not git_version:
                status = "never_committed"
            elif git_version != read_file(output):
                status = "uncommitted_changes"
            else:
                status = "stale"
        
        stale.append({
            "output": output,
            "reasons": reasons,
            "status": status
        })
    
    return stale
```

**Error E004: Stale Documentation**
```
Error: Generated documentation is stale

3 docs need regeneration:

  docs/how-it-works.md
    Status: stale (committed but outdated)
    Reason: sources changed
    Changed deps: docs/how-it-works.md (lines 118-120 added)

  docs/getting-started.md
    Status: stale (committed but outdated)
    Reason: prompt changed
    Instruction changes: 15 lines modified

  docs/overview.md
    Status: never_committed
    Reason: sources and prompt changed

Fix: Run `bin/graft rebuild` to regenerate all stale docs
Or: Run `bin/graft rebuild docs/how-it-works.md` for specific file
```

**Exit code**: 1 (in strict modes), 0 (in report-only mode)

### Layer 3: Content Validation

**Purpose**: Verify outputs match their inputs through regeneration  
**Performance**: ~30s per doc (depends on LLM latency)  
**Execution**: Full regeneration and byte-level comparison

#### 3.1 Regeneration Verification

**Algorithm**:
```python
def validate_content(outputs=None):
    """
    Regenerate docs and compare to committed versions.
    
    Args:
        outputs: List of specific outputs to validate, or None for all
    """
    mismatches = []
    
    # Determine which outputs to check
    if outputs is None:
        # All outputs from all prompts
        outputs = [
            parse_frontmatter(p)["out"] 
            for p in glob("**/*.prompt.md", recursive=True)
        ]
    
    for output in outputs:
        # Get committed version from git HEAD
        committed = subprocess.run(
            ["git", "show", f"HEAD:{output}"],
            capture_output=True
        ).stdout
        
        if not committed:
            # Never committed, skip comparison
            continue
        
        # Regenerate
        subprocess.run(["bin/graft", "rebuild", output], check=True)
        
        # Compare
        regenerated = read_file(output)
        
        if committed != regenerated:
            diff = unified_diff(
                committed.decode(), 
                regenerated, 
                fromfile=f"HEAD:{output}",
                tofile=f"regenerated:{output}"
            )
            
            mismatches.append({
                "output": output,
                "diff": diff,
                "lines_changed": len(diff.split("\n"))
            })
    
    if mismatches:
        raise ValidationError("E005", mismatches=mismatches)
```

**Error E005: Output Mismatch**
```
Error: Generated output doesn't match committed version

File: docs/api-reference.md
Regeneration produced different content (247 lines changed)

Diff preview (first 20 lines):
--- HEAD:docs/api-reference.md
+++ regenerated:docs/api-reference.md
@@ -45,7 +45,7 @@
-### Authentication
+### Authentication & Authorization
 
-The API uses bearer tokens.
+The API uses OAuth 2.0 bearer tokens.
...

This means either:
1. You edited the generated file directly (edit the .prompt.md instead)
2. Sources/prompts changed but output wasn't regenerated before committing
3. LLM non-determinism (rare, regenerate again to verify)

Fix: Run `bin/graft rebuild docs/api-reference.md` and commit the result
```

**Exit code**: 1

#### 3.2 Signature Verification

**Algorithm**:
```python
def verify_signatures():
    """
    Check Graft signatures match current sources/prompts.
    """
    errors = []
    
    for prompt_file in glob("**/*.prompt.md", recursive=True):
        frontmatter = parse_frontmatter(prompt_file)
        output = frontmatter["out"]
        
        if not os.path.exists(output):
            continue
        
        # Extract signature from output
        output_content = read_file(output)
        sig_match = re.search(r'sig=([a-f0-9]{64})', output_content)
        
        if not sig_match:
            errors.append({
                "output": output,
                "type": "missing_signature"
            })
            continue
        
        stored_sig = sig_match.group(1)
        
        # Compute expected signature
        deps = frontmatter.get("deps", [])
        model = frontmatter.get("model", "bedrock-claude-v4.5-sonnet-us")
        
        # Signature is hash of: sources + prompt + model + revision
        hasher = hashlib.sha256()
        
        # Add all dependencies
        for dep in deps:
            for file in expand_glob(dep):
                hasher.update(read_file(file))
        
        # Add prompt body
        hasher.update(extract_prompt_body(read_file(prompt_file)))
        
        # Add model
        hasher.update(model.encode())
        
        # Add git revision
        rev = subprocess.run(
            ["git", "rev-parse", "--short", "HEAD"],
            capture_output=True,
            text=True
        ).stdout.strip
