<!-- Generated by Graft | model=bedrock-claude-v4.5-sonnet-us | sig=6ecf36b9d8b398771ab2e4960bc48329155a7bee6f895f8a85bbcddbbbb793e8 | rev=39b5c7a | 2025-11-04 -->
# How It Works - Technical Architecture

Graft is a pipeline system that maintains strategic documentation using LLMs and DVC. This document explains the technical architecture, change detection mechanisms, and pipeline management that enable intelligent, incremental document generation.

## Architecture Overview

Graft consists of five interconnected components:

1. **Source documents** - Markdown files containing raw information (e.g., `docs/onboarding/team-structure.md`, `docs/metrics/q4-results.md`)
2. **Prompt files** - Special `*.prompt.md` files that define how to synthesize sources into output documents, including frontmatter with dependencies and generation instructions
3. **Pack prompt** (`scripts/pack_prompt.py`) - Change detection engine that analyzes git history to determine what changed and generates packed prompts with appropriate directives
4. **Render** (`scripts/render_llm.sh`) - LLM invocation wrapper that handles retries, credential management, and model selection
5. **Generate** (LLM execution) - Claude processes the packed prompt and generates output following the specified directive

The flow:

```
Source docs ──┐
              ├─→ pack_prompt.py ──→ Packed prompt ──→ render_llm.sh ──→ LLM ──→ Output .md
Prompt file ──┘    (change detection)                  (invocation)
```

Each prompt file declares its dependencies in frontmatter. When sources or prompt instructions change, Graft detects this and passes precise directives to the LLM about what type of regeneration is needed.

## Change Detection

Graft tracks two independent types of changes:

### Source Changes

Detected by computing git diffs of all files listed in the `deps:` frontmatter array. The mechanism:

1. `pack_prompt.py` calls `git_unified_diff(paths)` which runs:
   ```
   git diff --unified=3 HEAD~1 HEAD -- [dep files]
   ```
2. If files haven't changed between commits, the diff is empty
3. Special markers distinguish new files (`@@ NEW FILE @@`) from existing content (`@@ CURRENT CONTENT @@`)
4. The complete unified diff is included in the packed prompt under `---BEGIN SOURCE DIFF---`

### Prompt Changes

Detected by comparing the prompt body (everything after frontmatter) between commits:

1. `get_prev_commit_content(args.prompt)` retrieves the prompt file from `HEAD~1`:
   ```python
   git show HEAD~1:path/to/file.prompt.md
   ```
2. Both current and previous versions are parsed with `parse_front_matter()` to extract the prompt body
3. String comparison determines if instructions changed: `prev_prompt_body.strip() != prompt_body.strip()`
4. If changed, both versions are included in the packed prompt for LLM comparison

The packed prompt structure includes distinct sections:

```
SYSTEM: [directive definitions and behavior rules]

CHANGE ANALYSIS:
- Source files: CHANGED | NO CHANGES
- Prompt instructions: CHANGED | NO CHANGES  
- Previous draft: EXISTS | NONE
- Action required: [directive with explanation]

USER:
---BEGIN PREVIOUS DRAFT---
[last generated output]
---END PREVIOUS DRAFT---

---BEGIN SOURCE DIFF---
[git unified diff or full content]
---END SOURCE DIFF---

---BEGIN STYLE PROMPT--- | ---BEGIN PREVIOUS/CURRENT STYLE PROMPT---
[generation instructions]
---END STYLE PROMPT---
```

## Actions and Directives

Graft uses five distinct directives, computed by logic in `pack_prompt.py` (lines 95-115):

### GENERATE
**When:** No previous draft exists (`not output_exists`)

**Why:** Initial document creation requires full synthesis from sources

**LLM behavior:** Create complete document from scratch using source content and style prompt

### UPDATE
**When:** Sources changed but prompt unchanged (`sources_changed and not prompt_changed`)

**Why:** Content updates should preserve existing structure and tone - only semantic changes needed

**LLM behavior:** Apply ONLY the changes evident in the source diff. Keep all other sections byte-identical. Do not rewrite sections unaffected by the diff.

**Directive text:** `"UPDATE (sources changed - apply semantic changes only)"`

### RESTYLE
**When:** Prompt changed but sources unchanged (`prompt_changed and not sources_changed`)

**Why:** Style/tone/structure instructions changed - document must be regenerated entirely with new guidance

**LLM behavior:** Rewrite the ENTIRE document to match the new style prompt. Preserve the same semantic content but change tone, structure, or presentation as directed. Compare PREVIOUS STYLE PROMPT vs CURRENT STYLE PROMPT to understand what changed.

**Directive text:** `"RESTYLE (prompt changed, sources unchanged - rewrite entire document with new style)"`

### REFRESH
**When:** Both sources and prompt changed (`sources_changed and prompt_changed`)

**Why:** Both content and instructions updated - full regeneration needed

**LLM behavior:** Apply source updates AND rewrite in the new style

**Directive text:** `"REFRESH (both changed - apply source updates AND new style)"`

### MAINTAIN
**When:** Nothing changed (`not sources_changed and not prompt_changed`)

**Why:** No updates required - avoid unnecessary LLM calls

**LLM behavior:** Output should be identical to previous draft

**Directive text:** `"MAINTAIN (no changes detected - keep document unchanged)"`

The system prompt (defined in `pack_prompt.py` lines 8-20) explicitly instructs Claude on how to interpret and apply each directive. Claude uses its reasoning capabilities to identify what changed and how to apply the directive correctly.

## Multi-level Documentation DAGs

Generated documents can serve as inputs to other prompts, creating hierarchies:

```
docs/metrics/
  q4-results.md (source)
  q4-analysis.prompt.md  →  q4-analysis.md (generated, level 1)
  
docs/strategy/
  exec-summary.prompt.md (deps: [docs/metrics/q4-analysis.md])
    → exec-summary.md (generated, level 2)
```

In this example:
- `q4-results.md` is manually maintained source data
- `q4-analysis.md` is generated from `q4-results.md` by `q4-analysis.prompt.md`
- `exec-summary.md` is generated from `q4-analysis.md` by `exec-summary.prompt.md`

When `q4-results.md` changes:
1. DVC detects dependency and runs `q4-analysis` stage
2. `pack_prompt.py` shows the diff in source, generates UPDATE directive
3. LLM updates `q4-analysis.md` with new information
4. DVC detects that `q4-analysis.md` changed, runs `exec-summary` stage
5. `pack_prompt.py` sees `q4-analysis.md` in the diff, generates UPDATE directive
6. LLM updates `exec-summary.md` to reflect cascaded changes

### DVC Efficiency

DVC manages this efficiently with these principles:

- **`cache: false` for outputs** - Generated markdown is small and git-tracked; no need for DVC cache
- **Git-tracked files** - All inputs and outputs live in git, no cache duplication
- **Change cascade** - DVC's DAG automatically propagates changes through dependency chains
- **Selective regeneration** - Only stages with changed dependencies execute; unchanged branches are skipped

The result: complex documentation hierarchies stay synchronized with minimal LLM calls.

## Auto-generated dvc.yaml

The `dvc.yaml` file defining all pipeline stages is generated automatically by `scripts/generate_dvc.py`. This script:

1. **Scans for prompts** - Finds all `**/*.prompt.md` files recursively
2. **Parses frontmatter** - Extracts `deps:` arrays using regex and YAML parsing
3. **Validates dependencies** - Checks that all listed deps exist, warns if missing
4. **Generates stage names** - Converts `docs/strategy/exec-summary.prompt.md` → `exec_summary`
5. **Constructs stages** - For each prompt:
   ```python
   stage = {
       "cmd": f"bash scripts/render_llm.sh --prompt {rel_prompt} --out {rel_out} --name {stage_name}",
       "deps": SCRIPT_DEPS + [rel_prompt] + content_deps,
       "outs": [{rel_out: {"cache": False}}]
   }
   ```
6. **Writes dvc.yaml** - Outputs complete pipeline definition with header comment

Common script dependencies (`SCRIPT_DEPS`) are automatically added to every stage:
- `scripts/render_llm.sh`
- `scripts/pack_prompt.py`
- `scripts/ensure_llm.py`

This ensures that changes to the pipeline machinery itself trigger full regeneration.

**Critical rule:** Never edit `dvc.yaml` manually. All changes come from `*.prompt.md` files. The workflow:
1. Create or modify a `*.prompt.md` file
2. Update its `deps:` frontmatter
3. Run `bin/graft rebuild` (which calls `generate_dvc.py`)
4. Commit both the prompt and regenerated `dvc.yaml`

## Git Hooks

The pre-commit hook (`.git/hooks/pre-commit`, installed by `bin/graft init`) enforces synchronization:

```bash
if ! git diff --quiet dvc.yaml $(find . -name "*.prompt.md"); then
    scripts/generate_dvc.py
    git add dvc.yaml
fi
```

**Detection:** Compares `dvc.yaml` with all `*.prompt.md` files

**Action:** If they're out of sync:
1. Regenerates `dvc.yaml` from prompts
2. Stages the updated `dvc.yaml` for commit
3. Allows commit to proceed

**Why:** Prevents commits where `dvc.yaml` doesn't match prompt files, which would cause pipeline failures

The hook runs automatically before every commit. You can bypass it with `git commit --no-verify` if needed for development, but production commits should always keep them synchronized.

## Docker Execution

All Graft commands run inside a standardized Docker container (`graftdocs/graft:latest`), providing:

**Benefits:**
- **Reproducible environment** - Exact Python, DVC, and llm versions across all machines
- **Isolated dependencies** - No conflicts with host Python packages
- **Portable credentials** - AWS config and environment variables mounted consistently
- **Version pinning** - Docker image tag controls exact tool versions

**Mechanism** (implemented in `bin/graft`):
```bash
docker run --rm -it \
  -v "$PWD:/workspace" \           # Mount working directory
  -v "$HOME/.aws:/root/.aws:ro" \  # Mount AWS credentials (read-only)
  -v "$HOME/.config/io.datasette.llm:/root/.config/io.datasette.llm" \  # Mount LLM config
  --env-file .env \                # Load environment variables
  -w /workspace \                  # Set working directory
  graftdocs/graft:latest \
  [command]
```

**Mounted volumes:**
- Working directory → `/workspace` (read-write)
- AWS credentials → `/root/.aws` (read-only, for Bedrock access)
- LLM configuration → `/root/.config/io.datasette.llm` (for model registry)

**Environment:**
- `.env` file loaded for `AWS_PROFILE`, `LLM_MODEL`, etc.
- All DVC commands run with these credentials

**Transparency:**
The `bin/graft` wrapper handles Docker invocation transparently. From the user perspective:
```bash
bin/graft run       # Feels like native command
bin/graft status    # But actually runs in container
```

This architecture ensures that "works on my machine" problems are eliminated - the same container runs in CI/CD, developer laptops, and production environments.

---

